{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(filename='/Users/hubatsl/Desktop/SPT/Us/SPT/Python/hide_code.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a0231872-635f-48ff-8df4-5a113fde1afc"
    }
   },
   "source": [
    "# Off rate databank for pkc-ts experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import mlab \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import tifffile\n",
    "import time\n",
    "# Add path to python modules\n",
    "sys.path.append(os.getcwd()[0:-11]+'src/') \n",
    "from MovieTracks import (DiffusionFitter, OffRateFitter, ParticleFinder)\n",
    "# Plotting becomes part of the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Run thresholding on movie movieNo, read and write threshold from excel file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xls_file = '/Users/hubatsl/Desktop/Florent/OffRateFigureFlorent/OffRateTS.xlsx'\n",
    "xls_db = pd.read_excel(xls_file)\n",
    "movieNo = 0\n",
    "\n",
    "if np.isnan(xls_db['Threshold'][movieNo]):\n",
    "    xls_db.loc[movieNo, 'Threshold']=1000\n",
    "thresh = int(xls_db['Threshold'][movieNo])\n",
    "if np.isnan(xls_db['StartFrame'][movieNo]):\n",
    "    xls_db.loc[movieNo, 'StartFrame'] = 0\n",
    "startFrame = int(xls_db.loc[movieNo, 'StartFrame'])\n",
    "if np.isnan(xls_db['MaxSize'][movieNo]):\n",
    "    xls_db.loc[movieNo, 'MaxSize'] = 0\n",
    "maxSize = int(xls_db.loc[movieNo, 'MaxSize'])\n",
    "\n",
    "def adj_thresh(calibFrame, thresh, maxSize, startFrame):\n",
    "    calibFrame = int(calibFrame)\n",
    "    thresh = int(thresh)\n",
    "    startFrame = int(startFrame)\n",
    "    maxSize = int(maxSize)\n",
    "    if maxSize is not 0: \n",
    "        maxSize = int(maxSize)\n",
    "        o = OffRateFitter(xls_db['Folder'][movieNo], thresh, pixelSize=0.120,\n",
    "                          maxsize=maxSize/10000, startFrame=startFrame, featSize=5)\n",
    "    else:\n",
    "        o = OffRateFitter(xls_db['Folder'][movieNo], thresh, pixelSize=0.120,\n",
    "                          maxsize=None, startFrame=startFrame)\n",
    "    print(xls_db['Folder'][movieNo])\n",
    "    o.plot_calibration(calibrationFrame=calibFrame)\n",
    "    xls_db.loc[movieNo, 'StartFrame'] = startFrame\n",
    "    xls_db.loc[movieNo, 'Threshold'] = thresh\n",
    "    xls_db.loc[movieNo, 'MaxSize'] = maxSize\n",
    "    xls_db.to_excel(xls_file)\n",
    "\n",
    "interact(adj_thresh, thresh=str(thresh), calibFrame='0', maxSize=str(maxSize),\n",
    "         startFrame=str(startFrame), __manual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Read time stamps for each movie, write to excel file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xls_db['IntervalReal'] = 'nan'\n",
    "xls_db['ExposureReal'] = 'nan'\n",
    "xls_db['Length'] = 'nan'\n",
    "for i, path in enumerate(xls_db['Folder']):\n",
    "    p = ParticleFinder(path)\n",
    "    xls_db.loc[i, 'IntervalReal'] = p.timestep\n",
    "    xls_db.loc[i, 'ExposureReal'] = p.exposure\n",
    "    xls_db.loc[i, 'Length'] = len(p.frames)\n",
    "xls_db.to_excel(xls_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offRates = []\n",
    "onRates = []\n",
    "bleachingRates = []\n",
    "for i in range(len(xls_db['Folder'])):\n",
    "    fol = xls_db.loc[i, 'Folder']\n",
    "    threshold = xls_db.loc[i, 'Threshold']\n",
    "    maxsize = xls_db.loc[i, 'MaxSize']\n",
    "    if int(maxsize) is 0:\n",
    "        maxsize=None\n",
    "    else: maxsize = float(maxsize)/10000\n",
    "    o = OffRateFitter(filePath=fol, threshold=threshold, maxsize=maxsize,\n",
    "                      parallel=False, pixelSize=0.12,\n",
    "                      saveFigs=True, showFigs=True, autoMetaDataExtract=True,\n",
    "                      featSize=5)\n",
    "    o.analyze()\n",
    "    o.plot_calibration(calibrationFrame=10)\n",
    "    o.fit_offRate([1, 2, 3, 4, 5, 6])\n",
    "    o.append_output_to_csv('/Users/hubatsl/Desktop/Florent/OffRateFigureFlorent/Off_ts.csv', o.gData())\n",
    "#     input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = o.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "from sklearn import mixture\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.mlab\n",
    "import numpy as np\n",
    "\n",
    "clf = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "data = df.loc[df['frame']==0].mass.tolist()\n",
    "print(len(data))\n",
    "data = [[x] for x in data if x <10000]\n",
    "print(len(data))\n",
    "clf.fit(data)\n",
    "m1, m2 = clf.means_\n",
    "w1, w2 = clf.weights_\n",
    "c1, c2 = clf.covariances_\n",
    "data = [item for sublist in data for item in sublist]\n",
    "\n",
    "rangeMin = 0\n",
    "rangeMax = 10000\n",
    "h = matplotlib.pyplot.hist(data, bins=50, range=(rangeMin, rangeMax), normed=True);\n",
    "plt.plot(range(rangeMin, rangeMax, 100),\n",
    "         w1*mlab.normpdf(range(rangeMin, rangeMax, 100), m1, np.sqrt(c1[0]))+\n",
    "         w2*mlab.normpdf(range(rangeMin, rangeMax, 100), m2, np.sqrt(c2[0])))\n",
    "# plt.plot(range(rangeMin, rangeMax, 100), \n",
    "#          w1*mlab.normpdf(range(rangeMin, rangeMax, 100), m1, np.sqrt(c1[0])))\n",
    "# plt.plot(range(rangeMin, rangeMax, 100),\n",
    "#          w2*mlab.normpdf(range(rangeMin, rangeMax, 100), m2, np.sqrt(c2[0])))\n",
    "plt.show()\n",
    "print(w1/(w1+w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "from sklearn import mixture\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.mlab\n",
    "import numpy as np\n",
    "\n",
    "clf = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "data = np.random.randn(1000)\n",
    "data = [[x] for x in data if x <0]\n",
    "clf.fit(data)\n",
    "m1, m2 = clf.means_\n",
    "w1, w2 = clf.weights_\n",
    "c1, c2 = clf.covariances_\n",
    "data = [item for sublist in data for item in sublist]\n",
    "\n",
    "rangeMin = int(np.floor(np.min(data)))\n",
    "rangeMax = int(np.ceil(np.max(data)))\n",
    "h = matplotlib.pyplot.hist(data, range=(rangeMin, rangeMax), normed=True);\n",
    "plt.plot(np.linspace(rangeMin, rangeMax),\n",
    "         w1*mlab.normpdf(np.linspace(rangeMin, rangeMax), m1, np.sqrt(c1[0]))+\n",
    "         w2*mlab.normpdf(np.linspace(rangeMin, rangeMax), m2, np.sqrt(c2[0])))\n",
    "# plt.plot(range(rangeMin, rangeMax, 100), \n",
    "#          w1*mlab.normpdf(range(rangeMin, rangeMax, 100), m1, np.sqrt(c1[0])))\n",
    "# plt.plot(range(rangeMin, rangeMax, 100),\n",
    "#          w2*mlab.normpdf(range(rangeMin, rangeMax, 100), m2, np.sqrt(c2[0])))\n",
    "plt.show()\n",
    "# print(w1/(w1+w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(m1)\n",
    "print(m2)\n",
    "print(w1)\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.mlab\n",
    "import numpy as np\n",
    "\n",
    "clf = mixture.GaussianMixture(n_components=1, covariance_type='full', means_init=[[0]])\n",
    "data = np.random.randn(1000)\n",
    "data = [[x] for x in data if x <0]\n",
    "# data = [[x] for x in data]\n",
    "clf.fit(data)\n",
    "data = [item for sublist in data for item in sublist]\n",
    "rangeMin = int(np.floor(np.min(data)))\n",
    "rangeMax = int(np.ceil(np.max(data)))\n",
    "h = matplotlib.pyplot.hist(data, range=(rangeMin, rangeMax), normed=True);\n",
    "plt.plot(np.linspace(rangeMin, rangeMax),\n",
    "         mlab.normpdf(np.linspace(rangeMin, rangeMax),\n",
    "                      clf.means_, np.sqrt(clf.covariances_[0]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "import matplotlib.mlab\n",
    "import numpy as np\n",
    "\n",
    "def gaus(bin_mid, params):\n",
    "    a1, x01, sigma1 = params    \n",
    "    return a1*np.exp(-(bin_mid-x01)**2/(2*sigma1**2))\n",
    "\n",
    "def gaus_obj(params, bin_mid, data):\n",
    "    return np.sum((data-gaus(bin_mid, params))**2)**0.5\n",
    "\n",
    "data = np.random.randn(500)\n",
    "data = data[data<0]\n",
    "rangeMin = int(np.floor(np.min(data)))\n",
    "rangeMax = int(np.ceil(np.max(data)))\n",
    "h = matplotlib.pyplot.hist(data, range=(rangeMin, rangeMax), normed=True)\n",
    "data = h[0]\n",
    "bin_mid = h[1][0:-1]+np.mean(np.diff(h[1]))/2\n",
    "opt_result = differential_evolution(gaus_obj, [(0.7, 0.9), (-0.1, 0.1), (0.9, 1.1)],\n",
    "                                    args=(gaus(bin_mid, [0.8, 0, 1]), [bin_mid]), strategy='randtobest1exp')\n",
    "plt.plot(bin_mid, gaus(bin_mid, opt_result.x), color = 'c')\n",
    "plt.plot(bin_mid, gaus(bin_mid, [0.8, 0, 1]))\n",
    "print(gaus_obj(opt_result.x, bin_mid, data))\n",
    "print(gaus_obj([0.8, 0, 1], bin_mid, data))\n",
    "print(opt_result.x)\n",
    "plt.plot(bin_mid, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = (2, 3, 7, 8, 9, 10, 44, -1, 2, 26, 1, -2, 0.5)\n",
    "def f1(z, *params):\n",
    "    x, y = z\n",
    "    a, b, c, d, e, f, g, h, i, j, k, l, scale = params\n",
    "    return (a * x**2 + b * x * y + c * y**2 + d*x + e*y + f)\n",
    "def f2(z, *params):\n",
    "    x, y = z\n",
    "    a, b, c, d, e, f, g, h, i, j, k, l, scale = params\n",
    "    return (-g*np.exp(-((x-h)**2 + (y-i)**2) / scale))\n",
    "def f3(z, *params):\n",
    "    x, y = z\n",
    "    a, b, c, d, e, f, g, h, i, j, k, l, scale = params\n",
    "    return (-j*np.exp(-((x-k)**2 + (y-l)**2) / scale))\n",
    "def f(z, *params):\n",
    "     return f1(z, *params) + f2(z, *params) + f3(z, *params)\n",
    "rranges = (slice(-4, 4, 0.25), slice(-4, 4, 0.25))\n",
    "from scipy import optimize\n",
    "resbrute = optimize.brute(f, rranges, args=params, full_output=True,\n",
    "                           finish=optimize.fmin)\n",
    "print(resbrute[0])  # global minimum\n",
    "print(resbrute[1])  # function value at global minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "def func(parameters, *data):\n",
    "\n",
    "    #we have 3 parameters which will be passed as parameters and\n",
    "    #\"experimental\" x,y which will be passed as data\n",
    "\n",
    "    a,b,c = parameters\n",
    "    x,y = data\n",
    "\n",
    "    result = 0\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result += (a*x[i]**2 + b*x[i]+ c - y[i])**2\n",
    "\n",
    "    return result**0.5\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #initial guess for variation of parameters\n",
    "    #             a            b            c\n",
    "    bounds = [(-10, 10), (-10, 10), (-10, 10)]\n",
    "\n",
    "    #producing \"experimental\" data \n",
    "    x = [i for i in range(6)]\n",
    "    y = [x**2 for x in x]\n",
    "\n",
    "    #packing \"experimental\" data into args\n",
    "    args = (x,y)\n",
    "\n",
    "    result = differential_evolution(func, bounds, args=args)\n",
    "    print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.loc[df['frame']==1].mass.tolist()\n",
    "gmm = mixture.GaussianMixture(n_components=3, covariance_type='full').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.r_[np.dot(np.random.randn(n_samples, 1), C)];X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "color_iter = itertools.cycle(['navy', 'c', 'cornflowerblue', 'gold',\n",
    "                              'darkorange'])\n",
    "\n",
    "\n",
    "def plot_results(X, Y_, means, covariances, index, title):\n",
    "    splot = plt.subplot(2, 1, 1 + index)\n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "            means, covariances, color_iter)):\n",
    "        v, w = linalg.eigh(covar)\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        u = w[0] / linalg.norm(w[0])\n",
    "        # as the DP will not use every component it has access to\n",
    "        # unless it needs it, we shouldn't plot the redundant\n",
    "        # components.\n",
    "        if not np.any(Y_ == i):\n",
    "            continue\n",
    "        plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color)\n",
    "\n",
    "        # Plot an ellipse to show the Gaussian component\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180. * angle / np.pi  # convert to degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "        ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        splot.add_artist(ell)\n",
    "\n",
    "    plt.xlim(-9., 5.)\n",
    "    plt.ylim(-3., 6.)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "# Number of samples per component\n",
    "n_samples = 500\n",
    "\n",
    "# Generate random sample, two components\n",
    "np.random.seed(0)\n",
    "C = np.array([[0.1]])\n",
    "X = np.r_[np.dot(np.random.randn(n_samples, 1), C)]\n",
    "\n",
    "# Fit a Gaussian mixture with EM using five components\n",
    "gmm = mixture.GaussianMixture(n_components=5, covariance_type='full').fit(X)\n",
    "plot_results(X, gmm.predict(X), gmm.means_, gmm.covariances_, 0,\n",
    "             'Gaussian Mixture')\n",
    "\n",
    "# Fit a Dirichlet process Gaussian mixture using five components\n",
    "dpgmm = mixture.BayesianGaussianMixture(n_components=5,\n",
    "                                        covariance_type='full').fit(X)\n",
    "plot_results(X, dpgmm.predict(X), dpgmm.means_, dpgmm.covariances_, 1,\n",
    "             'Bayesian Gaussian Mixture with a Dirichlet process prior')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(X); plt.show()\n",
    "gmm.means_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [python3Conda]",
   "language": "python",
   "name": "Python [python3Conda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "a41f9a71-3b14-46c8-8a57-da66739704d1",
    "theme": {
     "a41f9a71-3b14-46c8-8a57-da66739704d1": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "a41f9a71-3b14-46c8-8a57-da66739704d1",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
